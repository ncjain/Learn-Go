## Go Concurrency
goroutine is lightweight execution thread running in the background. goroutines are key ingredients to achieve concurrency in Go.

As goroutines are lightweight compared to OS threads, it is very common for a Go application to have thousands of goroutines
running concurrently. Concurrency can speed up application significantly as well as help us write code with separation of 
concerns (SoC).



## Goroutines
A goroutine is simply a function or method that is running in background concurrently with other goroutines. It’s not a function 
or method definition that determines if it is a goroutine, it is determined by how we call it.
Go provides a special keyword go to create a goroutine. When we call a function or a method with go prefix, that function or 
method executes in a goroutine.

Example 1:
func main(){
	fmt.Println("Main goroutine started")
	go PrintHello()
	fmt.Println("Main goroutine is completed")
}
func PrintHello(){
	fmt.Println("Hello world started")
	fmt.Println("Hello world completed")
}
Output:
main execution started
main execution stopped

when we execute the above program, there are two goroutines running concurrently. As we saw in the earlier program, goroutines 
are scheduled cooperatively. Hence when the main goroutine starts executing, go scheduler dot not pass control to the printHello
goroutine until the main goroutine does not execute completely. Unfortunately, when the main goroutine is done with execution, 
the program terminates immediately and scheduler did not get time to schedule printHello goroutine. 

But as we know from other lessons, using blocking condition, we can pass control to other goroutines manually AKA telling the 
scheduler to schedule other available goroutines.

Note: 1. when the main goroutine is done with execution, the program terminates immediately and stop all the goroutines

Example 2:
package main
import (
	"fmt"
	"time"
)
func main(){
	fmt.Println("Main goroutine started")
	go PrintHello()
	time.Sleep(10 * time.Millisecond)
	fmt.Println("Main goroutine is completed")
}
func PrintHello(){
	fmt.Println("Hello world started")
	fmt.Println("Hello world completed")
}
Output:
Main goroutine started
Hello world started
Hello world completed
Main goroutine is completed

Example 3:
func printHello() {
	time.Sleep(time.Millisecond)
	fmt.Println("Hello World!")
}
func main() {
	fmt.Println("main execution started")
	go printHello()
	time.Sleep(10 * time.Millisecond)
	fmt.Println("main execution stopped")
}

Output:
main execution started
Hello World!
main execution stopped

Example 4:
func printHello() {
	time.Sleep(15 * time.Millisecond)
	fmt.Println("Hello World!")
}
func main() {
	fmt.Println("main execution started")
	go printHello()
	time.Sleep(10 * time.Millisecond)
	fmt.Println("main execution stopped")
}
Output:
main execution started
main execution stopped

Note 2: we learned that only non-sleeping goroutines are considered for scheduling, main won’t be scheduled again for 10 milli-seconds 
while it’s sleeping



## Working with multiple goroutines

Example 5:
package main
import (
	"fmt"
	"time"
)
func getChars(s string) {
	for _, c := range s {
		fmt.Printf("%c ", c)
	}
}
func getDigits(s []int) {
	for _, d := range s {
		fmt.Printf("%d ", d)
	}
}
func main() {
	fmt.Println("main execution started")
	go getChars("Hello")
	go getDigits([]int{1, 2, 3, 4, 5})
	time.Sleep(time.Millisecond) // schedule another goroutine
	fmt.Println("\nmain execution stopped")
}
main execution started
H e l l o 1 2 3 4 5 
main execution stopped

Note 3: It will schedule the goroutine whichever comes first then second and so on. which goroutines to schedule is determined by 
the scheduler. Above result again proves that goroutines are cooperatively scheduled.

Example 6:

package main
import (
	"fmt"
	"time"
)
var start time.Time
func init() {
	start = time.Now()
}
func getChars(s string) {
	for _, c := range s {
		fmt.Printf("%c at time %v\n", c, time.Since(start))
		time.Sleep(10 * time.Millisecond)
	}
}
func getDigits(s []int) {
	for _, d := range s {
		fmt.Printf("%d at time %v\n", d, time.Since(start))
		time.Sleep(30 * time.Millisecond)
	}
}
func main() {
	fmt.Println("main execution started at time", time.Since(start))
	go getChars("Hello")
	go getDigits([]int{1, 2, 3, 4, 5})
	time.Sleep(200 * time.Millisecond)
	fmt.Println("\nmain execution stopped at time", time.Since(start))
}

main execution started at time 0s
H at time 0s
1 at time 0s
e at time 10ms
l at time 20ms
l at time 30ms
2 at time 30ms
o at time 40ms
3 at time 60ms
4 at time 90ms
5 at time 120ms
main execution stopped at time 200ms

Now we understood how to create goroutine and how to work with them. But using time.Sleep is just a hack to see the result. 
In production, we don’t know how much time a goroutine is going to take for the execution. Hence we can't just add random sleep 
call in the main function. We want our goroutines to tell when they finished the execution. Also at this point, we don’t know 
how we can get data back from other goroutines or pass data to them, simply, communicate with them. This is where channels comes in.



## Anonymous Go routines
In Go language, you can also start Goroutine for an anonymous function or in other words, you can create an anonymous Goroutine 
simply by using go keyword as a prefix of that function as shown in the below Syntax:

// Anonymous function call
go func (parameter_list){
// statement
}(arguments)


Example 7:
func main(){
	fmt.Println("Main started")
	go func(){
		fmt.Println("Print Hello")
	}()
	time.Sleep(10*time.Millisecond)
	fmt.Println("Main completed")
}

Note 4: All goroutines are anonymous as we learned from concurrency lesson as goroutine does not have an identity. But we are calling 
that in the sense that function from which it was created was anonymous.


The parts of an application that run concurrently are called goroutines. Goroutines and channels are used for structuring concurrent 
programs.
A process is an independently executing entity running in a machine which runs in its own address space in memory. A process has 
threads which are simultaneously executing entities. Threads share the same address space of the process.

Goroutines are lightweight, much lighter than a thread. Goroutines run in the same address space, so access to shared memory must
be synchronized; This can be done by sync package, but it is recommended to use channels to synchronize goroutines.

A goroutine is implemented as a function or method. It is called (invoked) with the 'go' keyword. When the goroutine finishes, nothing 
is returned to the caller function.

It is advised in most of the cases, to run all your goroutines on one core but if you need to divide goroutines among available CPU 
cores of your system, you can use GOMAXPROCS environment variable or call to runtime using function runtime.GOMAXPROCS(n) where n is 
the number of cores to use. But you may sometime feel that setting GOMAXPROCS > 1 is making your program slower. It truly depends on 
the nature of your program but you can find a solution or explanation of your problem on the internet. In practical terms, programs 
that spend more time communicating on channels than doing computation will experience performance degradation when using multiple cores
, OS threads, and processes.



## What is a goroutine?
a goroutine is simply a function or method that is running in background concurrently with other goroutines. It’s not a function 
or method definition that determines if it is a goroutine, it is determined by how we call it.
Go provides a special keyword go to create a goroutine. When we call a function or a method with go prefix, that function or method 
executes in a goroutine.

All goroutines are anonymous as we learned from concurrency lesson as goroutine does not have an identity. But we are calling that
in the sense that function from which it was created was anonymous.


## Example 1:
package main  
import (  
   "fmt"  
   "time"   
)  
func main() {    
   go fun1()  
   go fun2()  
   fmt.Println("all done")   
}  
func fun1(){  
   for  i:=0;i<10;i++{  
	  fmt.Println("fun1,  ->",i)  
	  time.Sleep(time.Duration(5*time.Millisecond))  
   }    
}  
func fun2(){  
   for i:=0;i<10;i++{  
	  fmt.Println("fun2,  ->",i)  
	  time.Sleep(time.Duration(10*time.Millisecond))  
   }  
}  

Output:
fun1,  -> 0
fun2,  -> 0
all done
Main goroutine will not to complete other go routine. It will exit once it is done.



## Go WaitGroup
Let’s imagine a condition where you need to know if all goroutines finished their job. This is somewhat opposite to select where you
needed only one condition to be true, but here you need all conditions to be true in order to unblock the main goroutine. Here the 
condition is successful channel operation.

WaitGroup is a struct with a counter value which tracks how many goroutines were spawned and how many have completed their job. 
This counter when reaches zero, means all goroutines have done their job.

"sync"
var wg = sync.WaitGroup{} 
wg.Add(2)   
wg.Wait()
wg.Done()
wg.Done()

Example 2:

package main  
import (  
   "fmt"  
   "time"  
   "sync"  
)  
var wg = sync.WaitGroup{}  
  
func main() {  
   wg.Add(2)  
   go fun1()  
   go fun2()  
   wg.Wait()
   fmt.Println("all done")   
}  
func fun1(){  
   for  i:=0;i<10;i++{  
	  fmt.Println("fun1,  ->",i)  
	  time.Sleep(time.Duration(5*time.Millisecond))  
   }  
   wg.Done()  
}  
func fun2(){  
   for i:=0;i<10;i++{  
	  fmt.Println("fun2,  ->",i)  
	  time.Sleep(time.Duration(10*time.Millisecond))  
   }  
   wg.Done()  
}  
/*
fun1,  -> 0
fun2,  -> 0
fun1,  -> 1
fun2,  -> 1
fun1,  -> 2
fun1,  -> 3
fun2,  -> 2
fun1,  -> 4
fun1,  -> 5
fun2,  -> 3
fun1,  -> 6
fun1,  -> 7
fun2,  -> 4
fun1,  -> 8
fun2,  -> 5
fun1,  -> 9
fun2,  -> 6
fun2,  -> 7
fun2,  -> 8
fun2,  -> 9
all done
*/

Example 2.1:
import (
	"fmt"
	"sync"
	"time"
)

func service(wg *sync.WaitGroup, instance int) {
	time.Sleep(2 * time.Second)
	fmt.Println("Service called on instance", instance)
	wg.Done() // decrement counter
}
func main() {
	fmt.Println("main() started")
	var wg sync.WaitGroup // create waitgroup (empty struct)
	for i := 1; i <= 3; i++ {
		wg.Add(1) // increment counter
		go service(&wg, i)
	}
	wg.Wait() // blocks here
	fmt.Println("main() stopped")
}

main() started
Service called on instance 2
Service called on instance 3
Service called on instance 1
main() stopped

## Example 3:
package main  
import (  
   "sync"  
   "time"  
   "math/rand"  
   "fmt"  
)  
var wait sync.WaitGroup  
var count int  
func  increment(s string)  {  
   for i :=0;i<10;i++ {  
	  x := count  
	  x++;  
	  time.Sleep(time.Duration(rand.Intn(4))*time.Millisecond)  
	  count = x;  
	  fmt.Println(s, i,"Count: ",count)  
		
   }  
   wait.Done()	 
}  
func main(){  
   wait.Add(2)  
   go increment("foo: ")  
   go increment("bar: ")  
   wait.Wait()  
   fmt.Println("last count value " ,count)  
}  
/*
foo:  0 Count:  1
bar:  0 Count:  1
foo:  1 Count:  2
foo:  2 Count:  3
bar:  1 Count:  2
bar:  2 Count:  4
bar:  3 Count:  5
bar:  4 Count:  6
bar:  5 Count:  7
foo:  3 Count:  4
bar:  6 Count:  8
foo:  4 Count:  8
bar:  7 Count:  9
bar:  8 Count:  10
foo:  5 Count:  9
bar:  9 Count:  11
foo:  6 Count:  11
foo:  7 Count:  12
foo:  8 Count:  13
foo:  9 Count:  14
last count value  14
As you can see in the above example, the count resource is accessed by 2 go routines. Each routine iterates to 10 times. In such case,
the count variable should be 20 at last. But it is not so because it is simulating race condition.

*/



## Go Mutex
goroutines have their independent stack and hence they don’t share any data between them. But there might be conditions where some 
data in heap is shared between multiple goroutines. In that case, multiple goroutines are trying to manipulate data at the same memory 
location resulting in unexpected results.

Mutual Exclusion locks, or mutexes can be used to synchronize access to state and safely access data across many goroutines. It acts 
as a guard to the entrance of the critical section of code so that only one thread can enter the critical section at a time.

We set a lock around particular lines of code with it. While one Goroutine holds the lock, all other Goroutines are prevented from 
executing any lines of code protected by the same mutex, and are forced to wait until the lock is yielded before they can proceed.
var mutex sync.Mutex
mutex.Lock()
mutex.Unlock() 

Example : without mutax

import (
	"fmt"
	"sync"
)
var i int // i == 0
// goroutine increment global variable i
func worker(wg *sync.WaitGroup) {
	i = i + 1
	wg.Done()
}
func main() {
	var wg sync.WaitGroup
	for i := 0; i < 1000; i++ {
		wg.Add(1)
		go worker(&wg)
	}
	// wait until all 1000 gorutines are done
	wg.Wait()
	// value of i should be 1000
	fmt.Println("value of i after 1000 operations is", i)
}
value of i after 1000 operations is 940

Example: with Mutax

import (
	"fmt"
	"sync"
)
var i int // i == 0
func worker(wg *sync.WaitGroup, m *sync.Mutex) {
	m.Lock() // acquire lock
	i = i + 1
	m.Unlock() // release lock
	wg.Done()
}
func main() {
	var wg sync.WaitGroup
	var m sync.Mutex
	for i := 0; i < 1000; i++ {
		wg.Add(1)
		go worker(&wg, &m)
	}
	wg.Wait()
	fmt.Println("value of i after 1000 operations is", i)
}
output: value of i after 1000 operations is 1000


package main  
import (  
   "sync"  
   "time"  
   "math/rand"  
   "fmt"  
)  
var wait sync.WaitGroup  
var count int  
var mutex sync.Mutex  
func  increment(s string)  {  
   for i :=0;i<10;i++ {  
	  mutex.Lock()  
	  x := count  
	  x++;  
	  time.Sleep(time.Duration(rand.Intn(10))*time.Millisecond)  
	  count = x;  
	  fmt.Println(s, i,"Count: ",count)  
	  mutex.Unlock()  
		
   }  
   wait.Done()  
	 
}  
func main(){  
   wait.Add(2)  
   go increment("foo: ")  
   go increment("bar: ")  
   wait.Wait()  
   fmt.Println("last count value " ,count)  
}  
/*
bar:  0 Count:  1
bar:  1 Count:  2
foo:  0 Count:  3
bar:  2 Count:  4
foo:  1 Count:  5
bar:  3 Count:  6
foo:  2 Count:  7
bar:  4 Count:  8
foo:  3 Count:  9
foo:  4 Count:  10
bar:  5 Count:  11
foo:  5 Count:  12
bar:  6 Count:  13
foo:  6 Count:  14
bar:  7 Count:  15
foo:  7 Count:  16
bar:  8 Count:  17
foo:  8 Count:  18
bar:  9 Count:  19
foo:  9 Count:  20
last count value  20
*/




## Go Atomic Variable
Atomic variables are used to manage state, though sync/atomic package and avoid race conditions. Atomic counters can be accessed 
by multiple go routines.
"sync/atomic" 
var count int64  
atomic.AddInt64(&count,10) 

package main  
import (  
   "sync"  
   "time"  
   "math/rand"  
   "fmt"  
   "sync/atomic"  
)  
var wait sync.WaitGroup  
var count int64  
func  increment(s string)  {  
   for i :=0;i<10;i++ {  
      time.Sleep(time.Duration((rand.Intn(3)))*time.Millisecond)  
      atomic.AddInt64(&count,10)  
      fmt.Println(s,i,"Count ->",count)  
   }  
   wait.Done()  
}  
func main(){  
   wait.Add(2)
   go increment("foo: ")
   go increment("bar: ")
   wait.Wait()
   fmt.Println("last count value " ,count)  
} 

/*
bar:  0 Count -> 10
bar:  1 Count -> 30
foo:  0 Count -> 30
foo:  1 Count -> 40
foo:  2 Count -> 50
bar:  2 Count -> 60
foo:  3 Count -> 70
bar:  3 Count -> 90
bar:  4 Count -> 100
foo:  4 Count -> 90
foo:  5 Count -> 110
foo:  6 Count -> 120
bar:  5 Count -> 130
foo:  7 Count -> 140
bar:  6 Count -> 150
bar:  7 Count -> 160
foo:  8 Count -> 170
bar:  8 Count -> 180
foo:  9 Count -> 200
bar:  9 Count -> 200
last count value  200
*/



## Go Channel
The channel acts as a pipe by which we send typed values from one Goroutine to another. It guarantees synchronization since only one
Goroutine has access to a data item at any given time. The ownership of the data is passed between different Goroutine. Hence, By design
it avoids the pitfalls of shared memory and prevent race condition.


package main  
import "fmt"  
import "time"  
func worker(done chan bool) {  
   fmt.Print("working...")  
   time.Sleep(time.Second)  
   fmt.Println("done")  
   done <- true  
}  
func main() {  
   done := make(chan bool, 1)  
   go worker(done)  
   <-done  
}  



Advantages of Goroutines

    Goroutines are cheaper than threads.
    Goroutine are stored in the stack and the size of the stack can grow and shrink according to the requirement of the program. But 
    in threads, the size of the stack is fixed.
    Goroutines can communicate using the channel and these channels are specially designed to prevent race conditions when accessing 
    shared memory using Goroutines.
    Suppose a program has one thread, and that thread has many Goroutines associated with it. If any of Goroutine blocks the thread due 
    to resource requirement then all the remaining Goroutines will assign to a newly created OS thread. All these details are hidden 
    from the programmers.




## What are the channels?

A channel is a communication object using which goroutines can communicate with each other. Technically, a channel is a data transfer
pipe where data can be passed into or read from. Hence one goroutine can send data into a channel, while other goroutines can read that
data from the same channel.
Declaring a channel

Go provides chan keyword to create a channel. A channel can transport data of only one data type. No other data types are allowed to 
be transported from that channel.

func main(){
var a chan int 
fmt.Print(a)
}
program declares a channel c which can transport data type of int. Above program prints <nil> because zero-value of a channel is nil

func main(){
a := make(chan int)
fmt.Printf("%T", a)
fmt.Printf("%v", a)
}

We have used short-hand syntax := to make a channel using make function. The above program yields the following result.

type of `c` is chan int
value of `c` is 0xc0420160c0

Notice value of the channel c. Looks like it is a memory address. Channels by default are pointers. Mostly, when you want to communicate
with a goroutine, you pass the channel as an argument to the function or method. Hence when goroutine receives that channel as an
argument, you don’t need to dereference it to push or pull data from that channel.



## Data read and write
Go provide very easy to remember left arrow syntax <- to read and write data from a channel.

c <- data

Above syntax means, we want to push or write data to the channel c. Look at the direction of the arrow. It points from data to channel 
c. Hence we can imagine that we are trying to push data to c.

<- c

Above syntax means, we want to read some data from channel c. Look at the direction of the arrow, it starts from the channel c. This 
statement does not push data into anything, but still, it’s a valid statement. If you have a variable that can hold the data coming 
from the channel, you can use below syntax

var data int
data = <- c

Now data coming from the channel c which is of type int can be stored into the variable data of type int.
Above syntax can be re-written using shorthand syntax as below

data := <- c


o will figure out the data type of data being transported in channel c and gives data a valid data type.

All the above channel operations are blocking by default. In the previous lesson, we saw time.Sleep blocking a goroutine. Channel 
operations are also blocking in nature. When some data is written to the channel, goroutine is blocked until some other goroutine 
reads it from that channel. At the same time, as we seen in concurrency chapter, channel operations tell the scheduler to schedule
another goroutine, that’s why a program doesn’t block forever on the same goroutine. These features of a channel are very useful in
goroutines communication as it prevents us from writing manual locks and hacks to make them work with each other.


Example 1:
package main  
import "fmt"  
func greet(c chan string){
fmt.Println("Hello "+ <-c + "!")
}
func main(){
fmt.Println("main started")
c :=make(chan string)
go greet(c)

c <- "Kapil"
fmt.Println("main stopped")
}
main started
HelloKapil!
main stopped




1. We declared greet function which accepts a channel c of transport data type string. In that function, we are reading data from the
channel c and printing that data to the console.
2. In the main function, program prints main started to the console as it is the first statement.
3. Then we made the channel c of type string using make function.
4. We passed channel c to the greet function but executed it as a goroutine using go keyword.
5. At this point, the process has 2 goroutines while active goroutine is main goroutine (check the previous lesson to know what it is).
Then control goes to the next line.
6. We pushed a string value John to channel c. At this point, goroutine is blocked until some goroutine reads it. Go scheduler schedule
greet goroutine and it’s execution starts as per mentioned in the first point.
7. Then main goroutine becomes active and execute the final statement, printing main stopped.



## Deadlock

As discussed, when we write or read data from a channel, that goroutine is blocked and control is passed to available goroutines.
What if there are no other goroutines available, imagine all of them are sleeping. That’s where deadlock error occurs crashing the 
whole program.

If you are trying to read data from a channel but channel does not have a value available with it, it blocks the current goroutine 
and unblocks other in a hope that some goroutine will push a value to the channel. Hence, this read operation will be blocking. 
Similarly, if you are to send data to a channel, it will block current goroutine and unblock others until some goroutine reads the 
data from it. Hence, this send operation will be blocking.


Example 2:
package main  
import "fmt"  

func main(){
fmt.Println("main started")
c := make(chan string)
c <- "Kapil"
fmt.Println("main stopped")
}


main started
fatal error: all goroutines are asleep - deadlock!
goroutine 1 [chan send]:
main.main()
        C:/Users/kapil_jain/Desktop/test.go:7 +0xb4
exit status 2




## Closing a channel

A channel can be closed so that no more data can be sent through it. Receiver goroutine can find out the state of the channel using 
val, ok := <- channel syntax where ok is true if the channel is open or read operations can be performed and false if the channel is 
closed and no more read operations can be performed. 
A channel can be closed using close built-in function with below syntax.

close(channel)


Example 3:  
func greet(c chan string){
<-c
<-c
}

func main(){
fmt.Println("main started")
c :=make(chan string)
go greet(c)

c <- "Kapil"
close(c)

c <- "Jain"
fmt.Println("main stopped")
}

/*
main started
Kapil
panic: send on closed channel
goroutine 1 [running]:
main.main()
        C:/Users/kapil_jain/Desktop/test.go:16 +0xfe
exit status 2
*/

Just to help you understand blocking concept, first send operation c <- "John" is blocking and some goroutine has to read data from 
the channel, hence greet goroutine is scheduled by the Go Scheduler. Then first read operation <-c is non-blocking because data is
present in channel c to be read from. Second read operation <-c will be blocking because channel c does not have any data to be read
from, hence Go Scheduler activates main goroutine and program starts execution from close(c) function.


When channel is closed, value read by the goroutine is zero value of the data type of the channel. In this case, since channel 
is transporting int data type, it will be 0 as we can see from the result.

To avoid the pain of manually checking for channel closed condition, Go gives easier for range loop which will automatically close 
when the channel is closed. Let’s modify our previous above program.

## Note: If you don’t close the channel in for range loop, program will throw deadlock fetal error in runtime.



Buffer size or channel capacity


default case

Like switch statement, select statement also has default case. A default case is non-blocking. But that’s not all, default case 
makes select statement always non-blocking. That means, send and receive operation on any channel (buffered or unbuffered) is 
always non-blocking.

If a value is available on any channel then select will execute that case. If not then it will immediately execute the default case.


Deadlock

default case is useful when no channels are available to send or receive data. To avoid deadlock, we can use default case. This is
possible because all channel operations due to default case are non-blocking, Go does not schedule any other goroutines to send data
to channels if data is not immediately available.
